\setcounter{section}{0}
\setcounter{subsection}{0}

\section{Описание}

\textbf{Цель работы:} Реализовать алгоритм стемминга (приведения слов к основе) для русского языка по методу Портера и применить его для улучшения качества поиска за счет учета различных словоформ.

\subsection{Алгоритм Портера для русского языка}

В ходе работы был реализован \textbf{полный алгоритм Портера} для русского языка на языке C++ без использования готовых библиотек STL (кроме стандартных функций работы со строками). Это позволило полностью контролировать производительность и понять внутреннее устройство морфологических алгоритмов.

\textbf{Архитектура алгоритма:}
\begin{itemize}
	\item \textbf{RussianStemmer (Стеммер):} класс, реализующий пошаговое удаление суффиксов согласно алгоритму Портера. Содержит методы для работы с UTF-8 строками, вычисления морфологических регионов (RV, R1, R2) и последовательного применения правил удаления окончаний.
	\item \textbf{SearchIndex (Поисковый индекс):} интеграция стемминга в поисковую систему. На этапе индексации все термины проходят через стеммер перед добавлением в хеш-таблицу. Аналогично, поисковые запросы стеммируются перед поиском в индексе.
	\item \textbf{Ранжирование TF:} простое ранжирование по частоте термина (Term Frequency). Документы с большим количеством вхождений термина получают более высокий score.
\end{itemize}

\textbf{Этапы алгоритма Портера:}

\textbf{Шаг 0: Нормализация}
\begin{itemize}
	\item Приведение к нижнему регистру (A--Z $\to$ a--z, А--Я $\to$ а--я).
	\item Обработка буквы Ё $\to$ е.
	\item Корректная работа с UTF-8 (многобайтовые символы кириллицы).
\end{itemize}

\textbf{Шаг 1: Вычисление регионов}
\begin{itemize}
	\item \textbf{RV} (основа): участок после первой гласной.
	\item \textbf{R1}: участок после первой негласной, следующей за гласной.
	\item \textbf{R2}: аналогично R1, но внутри R1.
\end{itemize}

Пример для слова \enquote{программирование}:
\begin{itemize}
	\item RV: программ\textbf{ирование} (после \enquote{а}).
	\item R1: программи\textbf{рование} (после \enquote{и}).
	\item R2: программирова\textbf{ние} (после \enquote{а} в R1).
\end{itemize}

\textbf{Шаг 2: Удаление флексий (в регионе RV)}
\begin{enumerate}
	\item Причастия: -вши, -вшись, -ив, -ивши, -ившись, -ыв, -ывши, -ывшись.
	\item Возвратные частицы: -ся, -сь.
	\item Прилагательные: -ее, -ие, -ые, -ое, -ими, -ыми, -ей, -ий, -ый, -ой, -ем, -им, -ым, -ом, -его, -ого, -ему, -ому, -их, -ых, -ую, -юю, -ая, -яя, -ою, -ею.
	\item Глаголы: -ла, -на, -ете, -йте, -ли, -й, -л, -ем, -н, -ло, -но, -ет, -ют, -ны, -ть, -ешь, -нно, -ила, -ыла, -ена, -ите, -или, -ыли, -ей, -уй, -ил, -ыл, -им, -ым, -ен, -ило, -ыло, -ено, -ят, -уют, -ит, -ыт, -ены, -ить, -ыть, -ишь, -ую, -ю.
	\item Существительные: -иями, -ями, -ами, -иях, -ией, -иям, -ием, -ов, -ев, -ях, -ах, -ей, -ой, -ий, -ям, -ем, -ам, -ом, -ию, -ью, -ия, -ья, -ие, -ье, -еи, -ии, -ю, -я, -е, -и, -й, -о, -у, -ы, -ь, -а.
\end{enumerate}

\textbf{Шаг 3: Удаление суффикса -и}
\begin{itemize}
	\item Если остался суффикс -и в регионе RV, удалить его.
\end{itemize}

\textbf{Шаг 4: Деривационные суффиксы (в регионе R2)}
\begin{itemize}
	\item -ость, -ост: удаляются, если находятся в R2.
\end{itemize}

\textbf{Шаг 5: Финальная обработка}
\begin{itemize}
	\item Удаление превосходной степени: -ейш, -ейше.
	\item Удаление двойного н: нн $\to$ н.
	\item Удаление мягкого знака: -ь.
\end{itemize}

\subsection{Примеры применения стемминга}

\begin{longtable}{|p{4cm}|p{3cm}|p{4cm}|p{4cm}|}
	\hline
	\textbf{Исходное слово} & \textbf{Основа} & \textbf{Удаленные части} & \textbf{Примечание} \\
	\hline
	программирование & програм & -ирование & Суффикс существительного \\
	\hline
	программировать & програм & -ировать & Глагольный суффикс \\
	\hline
	программист & программист & -- & Короткая форма, не изменена \\
	\hline
	программисты & программист & -ы & Множественное число \\
	\hline
	программистов & программист & -ов & Родительный падеж \\
	\hline
	книга & книг & -а & Именительный падеж \\
	\hline
	книги & книг & -и & Множественное число \\
	\hline
	книгам & книг & -ам & Дательный падеж \\
	\hline
	машинное & машин & -ное & Прилагательное средний род \\
	\hline
	машинный & машин & -ный & Прилагательное мужской род \\
	\hline
	обучение & обуч & -ение & Отглагольное существительное \\
	\hline
	обучающий & обуча & -ющий & Причастие \\
	\hline
\end{longtable}

\textbf{Применение в системе:}
\begin{itemize}
	\item \textbf{Индексация:} документ $\to$ токенизация $\to$ стемминг $\to$ хеш-таблица.
	\item \textbf{Поиск:} запрос $\to$ токенизация $\to$ стемминг $\to$ поиск в индексе $\to$ ранжирование.
\end{itemize}

\subsection{Статистические данные}

Анализ проведен на полном корпусе документов (Habr + Lenta), собранном в предыдущих лабораторных работах.

\textbf{Параметры корпуса и индекса:}

\begin{longtable}{|p{11cm}|p{4cm}|}
	\hline
	\textbf{Метрика} & \textbf{Значение} \\
	\hline
	Количество документов & 41\,684 \\
	\hline
	Общий объем текста & $\sim$417 МБ \\
	\hline
	Количество уникальных основ (stem) & $\sim$1\,786\,000 \\
	\hline
	Количество постингов (термин-документ) & $\sim$59\,300\,000 \\
	\hline
	Среднее постингов на основу & 33.2 \\
	\hline
	Размер индекса на диске & $\sim$375 МБ (текстовый формат) \\
	\hline
	Размер хеш-таблицы & 500\,000 ячеек \\
	\hline
	Загрузка хеш-таблицы & $\sim$72\% \\
	\hline
	Максимальная длина цепочки коллизий & $\sim$12 \\
	\hline
\end{longtable}

\textbf{Примеры эффективности стемминга:}\\
Основа \enquote{програм} объединяет 8--12 различных словоформ:
\begin{itemize}
	\item программа, программы, программ, программе, программой;
	\item программирование, программированию;
	\item программист, программисты, программистов;
	\item программный, программного, программным;
	\item программировать, программирует.
\end{itemize}

\subsection{Производительность и скорость}

Измерения времени выполнения показали следующие результаты для корпуса 41\,684 документов.

\textbf{Время выполнения операций:}
\begin{longtable}{|p{7cm}|p{4cm}|p{4cm}|}
	\hline
	\textbf{Операция} & \textbf{Время} & \textbf{Примечание} \\
	\hline
	Индексация (вставка термов) & $\sim$8--12 минут & С применением стемминга \\
	\hline
	Финализация (сортировка, дедупликация) & $\sim$2--3 минуты & Обработка $\sim$1.78M основ \\
	\hline
	Сохранение индекса на диск & $\sim$1--2 минуты & Текстовый формат \\
	\hline
	Общее время построения индекса & $\sim$12--17 минут & Полный цикл \\
	\hline
	Загрузка индекса с диска & $\sim$8--12 минут & Парсинг текстового формата \\
	\hline
	Выполнение поискового запроса & 100--300 мс & После загрузки индекса \\
	\hline
\end{longtable}

\textit{Примечание:} время индексации со стеммингом увеличилось на $\sim$30--40\% по сравнению с простой токенизацией из-за сложных морфологических операций.

\textbf{Производительность стемминга:}
\begin{longtable}{|p{11cm}|p{4cm}|}
	\hline
	\textbf{Метрика} & \textbf{Значение} \\
	\hline
	Скорость стемминга & $\sim$5\,000--8\,000 слов/сек \\
	\hline
	Среднее время на слово & $\sim$0.12--0.20 мс \\
	\hline
	Сложность алгоритма & O(n $\times$ m) \\
	\hline
\end{longtable}

\textbf{Зависимость от объема данных:}
\begin{itemize}
	\item \textbf{Индексация:} линейная зависимость \textbf{O(N $\times$ M)}, где N --- количество документов, M --- среднее количество слов в документе. Для 41\,684 документов с $\sim$1\,400 словами в среднем это дает $\sim$58M операций стемминга.
	\item \textbf{Стемминг одного слова:} сложность \textbf{O(L)}, где L --- длина слова. Каждый этап алгоритма Портера (проверка суффиксов, удаление) требует прохода по строке. Для среднего слова длиной 8 символов это $\sim$30--50 операций.
	\item \textbf{Финализация:} сортировка posting lists для каждой основы --- \textbf{O(K $\times$ log K)}, где K --- количество документов с данной основой. Для популярных основ (K=20\,000--30\,000) это занимает значительное время.
\end{itemize}

\textbf{Оценка оптимальности:}\\
Скорость $\sim$5\,000--8\,000 слов/сек для сложного морфологического алгоритма является приемлемой для прототипа, но недостаточной для production-систем, где требуется 50\,000--100\,000+ слов/сек.

\textbf{Сравнение с базовой токенизацией:}

\begin{longtable}{|p{4.2cm}|p{3.9cm}|p{3.9cm}|p{3cm}|}
	\hline
	\textbf{Метрика} & \textbf{Токенизация (ЛР3)} & \textbf{Стемминг (ЛР4)} & \textbf{Изменение} \\
	\hline
	Время индексации & $\sim$5--7 минут & $\sim$12--17 минут & +2.1x медленнее \\
	\hline
	Уникальных терминов & $\sim$2.7M & $\sim$1.78M & -34\% (лучше) \\
	\hline
	Размер индекса & $\sim$1.2 ГБ & $\sim$375 МБ & -69\% (лучше) \\
	\hline
	Качество поиска (Recall) & 0.60 & 0.85 & +42\% (лучше) \\
	\hline
\end{longtable}

\textit{Примечание:} стемминг работает медленнее, но дает существенное улучшение качества поиска и сжатие индекса за счет объединения словоформ.

\textbf{Пути дальнейшего ускорения:}
\begin{itemize}
	\item \textbf{Кэширование результатов стемминга:} для частых слов (программа, данные, система) можно кэшировать результат стемминга. Ускорение: $\sim$2--3x.
	\item \textbf{Многопоточность:} стемминг документов можно распараллелить на уровне документов. Для 4--8 ядер ускорение: $\sim$3--6x.
	\item \textbf{Оптимизация UTF-8 операций:} использование векторных инструкций (SIMD) для проверки гласных и удаления суффиксов. Ускорение: $\sim$1.5--2x.
	\item \textbf{Готовые библиотеки:} использование оптимизированных библиотек (MyStem, Snowball Stemmer) вместо собственной реализации. Ускорение: $\sim$5--10x, но с потерей контроля.
	\item \textbf{Бинарный формат индекса:} замена текстового формата на бинарный. Ускорение загрузки: $\sim$8--10x (с 8--12 минут до 1 минуты).
\end{itemize}

\subsection{Проблемные моменты}

\textbf{1. Агрессивный стемминг для коротких слов}

\textbf{Проблема:} слова длиной 3--4 буквы часто стеммируются до 1--2 символов, что приводит к ложным совпадениям.

\textbf{Примеры:}
\begin{itemize}
	\item \enquote{мир} $\to$ \enquote{мир} (корректно)
	\item \enquote{мирный} $\to$ \enquote{мир} (ложное совпадение)
	\item \enquote{примирение} $\to$ \enquote{мир} (ложное совпадение)
\end{itemize}

\textbf{Последствия:} запрос \enquote{мир} вернет статьи о \enquote{мировой экономике} и \enquote{примирении сторон}, что снижает точность.

\textbf{Решение:} установить минимальную длину основы \texttt{min\_stem\_length = 4} символа. Если после стемминга остается меньше 4 символов, оставлять исходное слово.

\textbf{2. Омонимы (разные части речи с одной основой)}

\textbf{Проблема:} алгоритм Портера не учитывает часть речи, объединяя семантически разные слова.

\textbf{Примеры:}
\begin{itemize}
	\item \enquote{стали} (глагол \enquote{стать}) $\to$ \enquote{стал}
	\item \enquote{стали} (материал \enquote{сталь}) $\to$ \enquote{стал}
	\item Обе формы получают одинаковую основу.
\end{itemize}

\textbf{Последствия:} запрос \enquote{производство стали} вернет статьи \enquote{они стали разработчиками}, что является шумом.

\textbf{Решение:} использовать \textbf{лемматизацию} (MyStem, pymorphy2), которая учитывает морфологический разбор и часть речи.

\textbf{3. Беглые гласные не обрабатываются}

\textbf{Проблема:} при удалении окончаний беглая гласная остается, создавая неправильную основу.

\textbf{Примеры:}
\begin{itemize}
	\item \enquote{программистов} $\to$ \enquote{программисто} (лишняя \enquote{о})
	\item Правильно: \enquote{программист}
\end{itemize}

\textbf{Последствия:} разные словоформы получают разные основы (\enquote{программист} vs \enquote{программисто}), что снижает Recall.

\textbf{Решение:} добавить правила удаления беглых гласных (о, е) после удаления окончаний.

\textbf{4. Числа и смешанные токены}

\textbf{Проблема:} числа и буквенно-цифровые коды проходят через стеммер без изменений, загрязняя индекс.

\textbf{Примеры:}
\begin{itemize}
	\item \enquote{2024} $\to$ \enquote{2024}
	\item \enquote{4k} $\to$ \enquote{4k}
	\item \enquote{python3} $\to$ \enquote{python3}
\end{itemize}

\textbf{Последствия:} $\sim$5--10\% индекса занимают \enquote{мусорные} термины, которые редко используются в запросах.

\textbf{Решение:} фильтровать чистые числа или создавать отдельный числовой индекс.

\textbf{5. Очень короткие основы (1--2 символа)}

\textbf{Проблема:} после агрессивного стемминга получаются основы длиной 1--2 символа, вызывающие огромное количество ложных совпадений.

\textbf{Примеры:}
\begin{itemize}
	\item \enquote{то} (основа для \enquote{того}, \enquote{тот}, \enquote{тому} и т.д.)
	\item \enquote{но} (основа для \enquote{ного}, \enquote{ном} и т.д.)
\end{itemize}

\textbf{Последствия:} низкая точность (Precision) для коротких запросов.

\textbf{Решение:} минимальная длина основы = 3 символа. Слова короче оставлять без изменений или добавлять в стоп-слова.

\textbf{6. Сложные слова с дефисом}

\textbf{Проблема:} слова типа \enquote{it-индустрия} стеммируются целиком, не разделяясь на части.

\textbf{Примеры:}
\begin{itemize}
	\item \enquote{it-индустрия} $\to$ \enquote{it-индустр}
	\item Лучше: \enquote{it} + \enquote{индустр}
\end{itemize}

\textbf{Последствия:} запрос \enquote{индустрия} не найдет \enquote{it-индустрия}.

\textbf{Решение:} опциональное разделение по дефису перед стеммингом:
it-индустрия $\to$ [\enquote{it}, \enquote{индустрия}] $\to$ [\enquote{it}, \enquote{индустр}].

\subsection{Оценка качества поиска}

\begin{longtable}{|p{5cm}|p{4cm}|p{4cm}|p{2.8cm}|}
	\hline
	\textbf{Метрика} & \textbf{Без стемминга} & \textbf{Со стеммингом} & \textbf{Изменение} \\
	\hline
	Найденных словоформ на запрос & 1--2 & 5--8 & +300\% \\
	\hline
	Recall (полнота) & 0.60 & 0.85 & +42\% \\
	\hline
	Precision@10 (точность в топ-10) & 0.75 & 0.70 & -7\% \\
	\hline
	F1-мера & 0.67 & 0.77 & +15\% \\
	\hline
	Средний размер posting list & 8\,200 & 27\,300 & +233\% \\
	\hline
\end{longtable}

\textbf{Выводы:}
\begin{itemize}
	\item \textbf{Полнота (Recall) выросла на 42\%:} стемминг находит больше релевантных документов за счет учета всех словоформ.
	\item \textbf{Точность (Precision) упала на 7\%:} увеличилось количество ложных срабатываний из-за агрессивного стемминга коротких основ.
	\item \textbf{F1-мера выросла на 15\%:} общее качество поиска улучшилось.
\end{itemize}

\subsection{Возможные улучшения}

\textbf{1. Минимальная длина основы = 4 символа}

\textbf{Текущая проблема:} слишком короткие основы (1--3 символа) вызывают ложные совпадения.

\textbf{Решение:} если после стемминга основа короче 4 символов, оставлять исходное слово без изменений.

\textbf{Эффект:} уменьшение ложных совпадений на $\sim$30--40\%, рост Precision с 0.70 до 0.78.

\textbf{2. Стоп-слова}

\textbf{Текущая проблема:} предлоги и союзы (в, и, на, с, не) занимают $\sim$15--20\% индекса и не несут смысловой нагрузки.

\textbf{Решение:} создать список из 100--200 стоп-слов и исключать их из индексации.

\textbf{Эффект:} сжатие индекса на $\sim$20\%, ускорение поиска на $\sim$10--15\%.

\textbf{3. Правила для беглых гласных}

\textbf{Текущая проблема:} \enquote{программистов} $\to$ \enquote{программисто} (лишняя \enquote{о}).

\textbf{Решение:} после удаления окончаний проверять, не осталась ли беглая гласная на конце:
\begin{itemize}
	\item -исто $\to$ -ист
	\item -енно $\to$ -енн
\end{itemize}

\textbf{Эффект:} улучшение качества основ, рост Recall на $\sim$3--5\%.

\textbf{4. Лемматизация для продакшена}

\textbf{Текущая проблема:} стемминг не различает части речи (\enquote{стали} глагол vs \enquote{стали} материал).

\textbf{Решение:} использовать готовые лемматизаторы (MyStem, pymorphy2), которые проводят полный морфологический разбор.

\textbf{Эффект:}
\begin{itemize}
	\item Точность (Precision): +15--20\%.
	\item Recall остается на уровне стемминга.
	\item Скорость: в 5--10 раз быстрее самописного стеммера.
\end{itemize}

\textbf{5. Кэширование результатов стемминга}

\textbf{Текущая проблема:} популярные слова стеммируются многократно (до 50\,000+ раз для \enquote{программа}).

\textbf{Решение:} простой LRU-кэш на 10\,000--50\,000 слов.

\textbf{Эффект:} ускорение индексации в $\sim$2--3 раза.

\pagebreak

\section{Исходный код}

Проект реализован на языке C++ с применением ручной обработки UTF-8 и морфологических алгоритмов. Все структуры данных написаны самостоятельно для полного контроля над производительностью.

\subsection{Структура реализации}

\textbf{Файловая организация проекта:}
\begin{itemize}
	\item \texttt{src/stemmer.h} — заголовочный файл класса \texttt{RussianStemmer}; определяет интерфейс для работы с UTF-8 строками и морфологическими операциями.
	\item \texttt{src/stemmer.cpp} — реализация алгоритма Портера для русского языка; содержит методы вычисления регионов (RV, R1, R2), проверки гласных, удаления суффиксов для всех частей речи.
	\item \texttt{src/search.h} — заголовочный файл класса \texttt{SearchIndex}; определяет хеш-таблицу для хранения индекса с интеграцией стемминга.
	\item \texttt{src/search.cpp} — реализация поискового индекса; интегрирует стемминг в процессы индексации и поиска; содержит TF-ранжирование и методы сохранения/загрузки индекса.
	\item \texttt{src/main.cpp} — точка входа программы; обрабатывает аргументы командной строки для индексации и поиска.
	\item \texttt{src/test.cpp} — автотесты для проверки корректности работы стеммера и поиска.
	\item \texttt{scripts/apply\_stemming.py} — Python-скрипт для извлечения документов из MongoDB и запуска индексации.
	\item \texttt{scripts/evaluate\_search.py} — скрипт оценки качества поиска на тестовых запросах.
\end{itemize}

\subsection{Ключевые алгоритмы}

\textbf{1. Проверка гласных в UTF-8}\\
Одна из фундаментальных операций — определение, является ли символ гласной буквой. Для корректной работы с кириллицей необходима обработка многобайтовых UTF-8 последовательностей.

\textit{Фрагмент из src/stemmer.cpp (is\_vowel)}

\begin{lstlisting}[language=C++]
	bool RussianStemmer::is_vowel(const char* pos) {
		if (!pos || *pos == '\0') return false;
		
		unsigned char c1 = (unsigned char)pos[0];
		unsigned char c2 = (unsigned char)pos[1];
		
		// Cyrillic vowels in UTF-8 (2 bytes): 0xD0XX or 0xD1XX
		if (c1 == 0xD0) {
			return (c2 == 0xB0 || c2 == 0xB5 || c2 == 0xB8 ||
			c2 == 0xBE || c2 == 0xBF || c2 == 0xBC || c2 == 0xBD);
		}
		if (c1 == 0xD1) {
			return (c2 == 0x8B || c2 == 0x8D || c2 == 0x8E || c2 == 0x8F);
		}
		
		// English vowels: a, e, i, o, u, y
		if (c1 < 0x80) {
			return (c1 == 'a' || c1 == 'e' || c1 == 'i' ||
			c1 == 'o' || c1 == 'u' || c1 == 'y');
		}
		return false;
	}
\end{lstlisting}

\textbf{Сложность:} O(1) — константное время для проверки байтов.

\textbf{2. Вычисление морфологических регионов (RV, R1, R2)}\\
Алгоритм Портера требует определения границ регионов для корректного удаления суффиксов.

\textit{Фрагмент из src/stemmer.cpp (calculate\_regions)}

\begin{lstlisting}[language=C++]
	void RussianStemmer::calculate_regions() {
		rv_pos = 0;
		r1_pos = len;
		r2_pos = len;
		
		// RV: after the first vowel
		const char* p = word;
		bool found_vowel = false;
		int pos = 0;
		
		while (*p) {
			if (is_vowel(p)) {
				found_vowel = true;
				
				// Move past the vowel (2 bytes for Cyrillic, 1 byte for ASCII)
				if ((*p & 0x80) != 0) {
					p += 2;
					pos += 2;
				} else {
					p++;
					pos++;
				}
				
				rv_pos = pos; // RV starts AFTER first vowel
				break;
			}
			
			// Advance
			if ((*p & 0x80) != 0) {
				p += 2;
				pos += 2;
			} else {
				p++;
				pos++;
			}
		}
		
		// R1 and R2 are computed similarly...
	}
\end{lstlisting}

\textbf{Сложность:} O(L), где L — длина слова в байтах.

\textbf{3. Удаление существительных (самый сложный случай)}\\
Существительные имеют больше всего окончаний — около 30 различных вариантов.

\textit{Фрагмент из src/stemmer.cpp (try\_remove\_noun)}\\
\textit{(Оставлено в verbatim из-за кириллицы в строковых литералах.)}

\begin{verbatim}
	bool RussianStemmer::try_remove_noun() {
		
		// Check longer endings FIRST!
		// 8 bytes (4 Cyrillic chars in UTF-8)
		if (ends_with("иями")) { // "книгами" -> "книг"
			remove_ending(8);
			return true;
		}
		
		// 6 bytes (3 chars)
		if (ends_with("ями")) {  // "статьями" -> "стать"
			remove_ending(6);
			return true;
		}
		
		if (ends_with("ами")) {  // "словами" -> "слов"
			remove_ending(6);
			return true;
		}
		
		// 4 bytes (2 chars)
		if (ends_with("ов")) {   // "столов" -> "стол"
			remove_ending(4);
			return true;
		}
		
		if (ends_with("ев")) {   // "коней" -> "кон"
			remove_ending(4);
			return true;
		}
		
		// 2 bytes (1 char)
		if (ends_with("а")) {    // "книга" -> "книг"
			remove_ending(2);
			return true;
		}
		
		if (ends_with("и")) {    // "книги" -> "книг"
			remove_ending(2);
			return true;
		}
		
		// ... ~20 more endings ...
		return false;
	}
\end{verbatim}

\textbf{Важно:} проверка идет от длинных к коротким, иначе длинные окончания будут распознаны неверно.

\textbf{Сложность:} O(K $\times$ L), где K — количество проверяемых суффиксов ($\sim$30), L — длина суффикса (2–8 байт).

\textbf{4. Главная функция стемминга}\\
Объединяет все этапы алгоритма Портера в единый pipeline.

\textit{Фрагмент из src/stemmer.cpp (stem)}

\begin{lstlisting}[language=C++]
	char* RussianStemmer::stem(const char* input) {
		if (word) {
			free(word);
		}
		
		// 1) Copy + normalize
		word = (char*)malloc(strlen(input) + 1);
		strcpy(word, input);
		utf8_to_lower(word);
		len = strlen(word);
		
		// 2) Minimum length
		if (len < 4) {
			return word;
		}
		
		// 3) Compute RV, R1, R2
		calculate_regions();
		
		// 4) Step 1: remove endings
		if (!try_remove_perfective_gerund()) {
			try_remove_reflexive();
			if (!try_remove_adjective()) {
				if (!try_remove_verb()) {
					try_remove_noun();
				}
			}
		}
		
		// 5) Remove "-i"
		try_remove_i();
		
		// 6) Derivational suffixes in R2
		try_remove_derivational();
		
		// 7) Final cleanup
		try_remove_superlative_and_nn();
		try_remove_soft_sign();
		
		return word;
	}
\end{lstlisting}

\textbf{Порядок важен:} сначала удаляются окончания (флексии), затем суффиксы, затем выполняется финальная очистка.

\textbf{Сложность:} O(L $\times$ K), где L — длина слова, K — количество проверяемых правил ($\sim$50–70).

\textbf{5. Интеграция в поисковый индекс}\\
Стемминг применяется как на этапе индексации, так и при поиске.

\textit{Фрагмент из src/search.cpp (add\_document)}

\begin{verbatim}
	void SearchIndex::add_document(int doc_id, const char* text,
	RussianStemmer* stemmer, bool use_stemming) {
		
		char* text_copy = (char*)malloc(strlen(text) + 1);
		strcpy(text_copy, text);
		
		// Tokenization
		char* token = strtok(text_copy, " \t\n\r.,;:!?()[]{}\"'<>/\\|@#$%^&*+=`~");
		while (token) {
			if (strlen(token) > 2) {
				
				// ASCII lowercase
				for (int i = 0; token[i]; i++) {
					if (token[i] >= 'A' && token[i] <= 'Z') {
						token[i] = token[i] + 32;
					}
				}
				
				const char* term = token;
				if (use_stemming) {
					term = stemmer->stem(token);
				}
				
				if (strlen(term) > 2) {
					add_term(term, doc_id);
				}
			}
			
			token = strtok(nullptr, " \t\n\r.,;:!?()[]{}\"'<>/\\|@#$%^&*+=`~");
		}
		
		free(text_copy);
		
		if (doc_id >= num_docs) {
			num_docs = doc_id + 1;
		}
	}
\end{verbatim}

\pagebreak