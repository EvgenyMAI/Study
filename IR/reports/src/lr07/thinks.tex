\section{Выводы}

В ходе выполнения лабораторной работы я получил практический опыт создания высокопроизводительных компонентов поисковых систем и научился оптимизировать алгоритмы для обработки больших объемов данных.

\begin{enumerate}
	\item \textbf{Реализация структур данных с нуля:} я научился создавать сложные структуры данных (хеш-таблицу, динамический массив) без использования готовых контейнеров STL. Это позволило глубоко понять устройство индексов и компромиссы между памятью и производительностью.
	\item \textbf{Профилирование и оптимизация:} наивная реализация (связные списки + сортировка при вставке) приводила к времени работы 30--60 минут из-за квадратичной сложности. Техника отложенной сортировки дала ускорение $\sim$100 раз для вставки и $\sim$20 раз для всего процесса индексации, а \texttt{memcpy} ускорил операции копирования примерно в $\sim$500 раз.
	\item \textbf{Алгоритмы на отсортированных данных:} операции AND/OR/NOT на отсортированных массивах через алгоритмы слияния со сложностью O(n + m) оказались эффективными при моем объеме данных, а сортировка один раз после индексации существенно ускоряет дальнейшие запросы.
	\item \textbf{Масштабируемость:} работа с корпусом 41\,818 документов и 2.7 млн терминов показала проблемы масштабирования (загрузка хеш-таблицы 100\%, длинные цепочки коллизий, медленная загрузка индекса 20--30 сек), что подтверждает необходимость бинарных форматов и кэширования для production-систем.
	\item \textbf{Понимание устройства поисковых систем:} стало ясно, почему индексация является оффлайн-процессом, почему индекс может быть больше исходных данных и почему даже булев поиск требует оптимизаций для больших коллекций.
\end{enumerate}

\pagebreak