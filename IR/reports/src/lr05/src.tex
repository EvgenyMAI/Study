\setcounter{section}{0}
\setcounter{subsection}{0}

\section{Описание}

\textbf{Цель работы:} Исследовать частотное распределение терминов в собранном текстовом корпусе и проверить его соответствие эмпирическим законам лингвистики (закону Ципфа и закону Мандельброта).

\subsection{Методика исследования}

Для выполнения работы использовался список токенов, полученный в результате выполнения лабораторной работы \textnumero 3. Исследование включало следующие этапы:
\begin{enumerate}
	\item \textbf{Потоковый подсчет частот:} из-за большого объема данных (680 МБ токенов) была реализована потоковая обработка файла без загрузки всего содержимого в оперативную память.
	\item \textbf{Фильтрация:} удаление артефактов HTML-разметки (слова типа \enquote{подписаться}, \enquote{комментарий}, \enquote{рейтинг}), которые создают искусственный шум в высокочастотной области.
	\item \textbf{Ранжирование:} сортировка терминов по убыванию частоты и присвоение им рангов.
	\item \textbf{Аппроксимация:} подбор констант для теоретических моделей (Ципфа и Мандельброта) и визуализация результатов в логарифмической шкале.
\end{enumerate}

\subsection{Статистические данные}

Анализ проводился на полном корпусе документов (Habr.com + Lenta.ru, 41\,684 документа).

\begin{longtable}{|p{11cm}|p{4cm}|}
	\hline
	\textbf{Метрика} & \textbf{Значение} \\
	\hline
	Общее количество токенов & 59\,029\,639 \\
	\hline
	Количество уникальных терминов & 1\,089\,797 \\
	\hline
	Самый частый термин & в (1\,604\,123 вхождений) \\
	\hline
\end{longtable}

\subsection{Параметры теоретических моделей}

Для аппроксимации реального распределения были подобраны следующие константы.

\textbf{Закон Ципфа:}
\begin{itemize}
	\item Константа C = 1\,604\,123 (частота термина ранга 1).
\end{itemize}

\textbf{Закон Мандельброта:}
\begin{itemize}
	\item C = 1\,604\,123
	\item B = 2.7 (сдвиг ранга)
	\item alpha = 1.00 (параметр степени)
\end{itemize}

\subsection{Графическое представление}

На графике ниже представлено распределение терминов в двойной логарифмической шкале (log-log plot).

\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.95\textwidth]{src/lr05/graph.png}
	\caption{Распределение частот терминов (log-log) с наложением законов Ципфа и Мандельброта.}
	\label{fig:zipf-graph}
\end{figure}

Синие точки соответствуют реальным данным корпуса. Красная линия — идеализированный закон Ципфа. Зеленая пунктирная линия — закон Мандельброта. Визуально график демонстрирует линейную зависимость в логарифмическом масштабе, что подтверждает применимость степенных законов к исследуемому корпусу.

\subsection{Анализ отклонений}

Было проведено детальное исследование отклонений реальных данных от теоретической кривой Ципфа в трех зонах.

\textbf{1. Высокочастотная зона (топ-100 терминов)}
\begin{itemize}
	\item \textbf{Среднее отклонение:} 145.9\%.
	\item \textbf{Причина:} доминирование стоп-слов; в русском языке служебные части речи используются интенсивно для грамматической связки слов, поэтому их частота убывает медленнее, чем предсказывает \enquote{чистый} закон Ципфа.
\end{itemize}

\textbf{2. Среднечастотная зона (ранги 100 -- 10\,000)}
\begin{itemize}
	\item \textbf{Среднее отклонение:} 312.2\% (максимальное).
	\item \textbf{Причина:} зона активной предметной лексики; поскольку корпус состоит из специфических тематик (IT и новости), отдельные термины (система, данные, россия, компания) встречаются чаще, чем в усредненном общеязыковом корпусе, создавая \enquote{выпуклость} на графике.
\end{itemize}

\textbf{3. Низкочастотная зона (ранги $>$ 10\,000)}
\begin{itemize}
	\item \textbf{Среднее отклонение:} 43.3\% (минимальное).
	\item \textbf{Причина:} \enquote{длинный хвост} распределения, состоящий из редких слов, опечаток и неологизмов; эта зона показала наилучшее соответствие теории, что свидетельствует о достаточном объеме корпуса для статистической достоверности.
\end{itemize}

\pagebreak

\section{Исходный код}

Для обработки массива данных объемом более 600 МБ был реализован эффективный скрипт на Python, использующий потоковую обработку данных (stream processing).

\subsection{Структура реализации}

Файловая организация проекта:
\begin{itemize}
	\item \texttt{scripts/calculate\_frequencies.py} — модуль подсчета частот; реализует чтение файла токенов через генератор, фильтрацию и агрегацию данных.
	\item \texttt{scripts/plot\_zipf.py} — модуль визуализации; строит график в matplotlib с логарифмическими осями.
	\item \texttt{scripts/analyze\_zipf.py} — модуль аналитики; вычисляет отклонения от теории в процентном соотношении.
	\item \texttt{run\_zipf.bat} — сценарий последовательного запуска всех этапов.
\end{itemize}

\subsection{Ключевые алгоритмы}

\textbf{1. Потоковая обработка (Lazy Loading)}
\begin{verbatim}
	def get_tokens_generator(tokens_file):
	"""
	Generator for streaming token reading.
	Uses errors='replace' to protect from broken utf-8 bytes.
	"""
	with open(tokens_file, 'r', encoding='utf-8', errors='replace') as f:
	for line in f:
	token = line.strip()
	if token:
	yield token  # Return one token at a time
\end{verbatim}

\textbf{2. Агрегация с фильтрацией}
\begin{verbatim}
	def calculate_frequencies_stream(tokens_file):
	counter = Counter()
	token_gen = get_tokens_generator(tokens_file)
	
	for token in tqdm(token_gen):
	if filter_garbage(token):  # Filter UI stopwords
	counter[token] += 1
	
	return counter.most_common()
\end{verbatim}

\textbf{3. Анализ отклонений}
\begin{verbatim}
	# Zipf: Frequency = C / Rank
	zipf_predicted = C / ranks
	
	# Relative deviation in %
	rel_deviations = (frequencies - zipf_predicted) / zipf_predicted * 100
	
	# Mean deviation by zones
	high_freq_dev = np.mean(np.abs(rel_deviations[:100]))
\end{verbatim}

\pagebreak
