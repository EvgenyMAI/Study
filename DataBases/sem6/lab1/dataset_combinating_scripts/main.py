import csv
import os
from faker import Faker
import uuid
import random
from concurrent.futures import ThreadPoolExecutor, as_completed

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ---
FILENAME = 'users.csv'
TOTAL_RECORDS = 5_000_000
BATCH_SIZE = 10_000
DOMAINS = ['gmail.com', 'yahoo.com', 'outlook.com', 'mail.net', 'yandex.ru', 'hotmail.com']
MAX_WORKERS = 8

fake = Faker()

def count_existing_records():
    """–°—á–∏—Ç–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ (–±–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞) –≤ –±–∏–Ω–∞—Ä–Ω–æ–º —Ä–µ–∂–∏–º–µ."""
    if not os.path.exists(FILENAME):
        return 0
    with open(FILENAME, 'rb') as f:
        total_lines = f.read().count(b'\n')
    return max(0, total_lines - 1)

def load_existing_emails():
    """
    –ß–∏—Ç–∞–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ email, –∏–≥–Ω–æ—Ä–∏—Ä—É—è NUL-–±–∞–π—Ç—ã.
    –ü—Ä–æ–ø—É—Å–∫–∞–µ–º null-—Å–∏–º–≤–æ–ª—ã –ø–µ—Ä–µ–¥ —Ä–∞–∑–±–æ—Ä–æ–º CSV.
    """
    emails = set()
    if not os.path.exists(FILENAME):
        return emails

    def sanitize_lines(f):
        for raw in f:
            # –∏–∑–±–∞–≤–ª—è–µ–º—Å—è –æ—Ç –≤—Å–µ—Ö '\0'
            yield raw.replace('\0', '')

    with open(FILENAME, 'r', encoding='utf-8', errors='ignore', newline='') as f:
        reader = csv.DictReader(sanitize_lines(f))
        for row in reader:
            email = row.get('email')
            if email:
                emails.add(email)
    return emails

def make_batch(n_records):
    users = []
    for _ in range(n_records):
        full_name = fake.name()
        email = f"{uuid.uuid4().hex}@{random.choice(DOMAINS)}"
        users.append({'email': email, 'full_name': full_name})
    return users

def write_batch(users):
    with open(FILENAME, 'a', newline='', encoding='utf-8') as csvfile:
        writer = csv.DictWriter(csvfile, fieldnames=['email', 'full_name'])
        writer.writerows(users)

def main():
    already = count_existing_records()
    to_go = TOTAL_RECORDS - already
    if to_go <= 0:
        print(f"‚úî –í —Ñ–∞–π–ª–µ —É–∂–µ {already} –∑–∞–ø–∏—Å–µ–π, –±–æ–ª—å—à–µ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω—É–∂–Ω–æ.")
        return

    print(f"–ù–∞–π–¥–µ–Ω–æ {already} –∑–∞–ø–∏—Å–µ–π, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –µ—â—ë {to_go}‚Ä¶")

    # –ï—Å–ª–∏ –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª ‚Äî —Å–æ–∑–¥–∞—ë–º –∏ –ø–∏—à–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
    if already == 0:
        with open(FILENAME, 'w', newline='', encoding='utf-8') as f:
            csv.DictWriter(f, fieldnames=['email', 'full_name']).writeheader()

    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ email (—Å –æ—á–∏—Å—Ç–∫–æ–π NUL)
    existing_emails = load_existing_emails()

    # –ì–æ—Ç–æ–≤–∏–º —Å–ø–∏—Å–∫–∏ —Ä–∞–∑–º–µ—Ä–æ–≤ –±–∞—Ç—á–µ–π
    full_batches = to_go // BATCH_SIZE
    last_batch = to_go % BATCH_SIZE
    batch_sizes = [BATCH_SIZE]*full_batches + ([last_batch] if last_batch else [])

    total_batches = len(batch_sizes)
    print(f"–ë—É–¥–µ—Ç –∑–∞–ø–∏—Å–∞–Ω–æ {total_batches} –ø–∞–∫–µ—Ç–æ–≤ –ø–æ {BATCH_SIZE} (–ø–æ—Å–ª–µ–¥–Ω–∏–π {last_batch or BATCH_SIZE}).")

    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as exe:
        futures = {
            exe.submit(make_batch, size): idx
            for idx, size in enumerate(batch_sizes, start=1)
        }
        for future in as_completed(futures):
            idx = futures[future]
            users = future.result()

            # –ü–æ–¥—Å—Ç—Ä–∞—Ö–æ–≤–∫–∞ –Ω–∞ —Ä–µ–¥–∫–∏–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è (—Ö–æ—Ç—å —Å uuid –æ–Ω–∏ –º–∞–ª–æ–≤–µ—Ä–æ—è—Ç–Ω—ã)
            for u in users:
                if u['email'] in existing_emails:
                    u['email'] = f"{uuid.uuid4().hex}@{random.choice(DOMAINS)}"
                existing_emails.add(u['email'])

            write_batch(users)
            print(f"‚úÖ –ü–∞–∫–µ—Ç {idx}/{total_batches} ({len(users)} –∑–∞–ø–∏—Å–µ–π) –∑–∞–ø–∏—Å–∞–Ω.")

    print(f"üéâ –í –∏—Ç–æ–≥–µ –≤ {FILENAME} ‚Äî —Ä–æ–≤–Ω–æ {TOTAL_RECORDS} –∑–∞–ø–∏—Å–µ–π.")

if __name__ == '__main__':
    main()