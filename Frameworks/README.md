# Прикладные системы и фреймворки искусственного интеллекта

Репозиторий содержит результаты пяти лабораторных работ по курсу «Прикладные системы и фреймворки искусственного интеллекта». Каждая лабораторная работа выполнена в формате Jupyter Notebook с подробными комментариями к каждой ячейке.

---

## Выполнил: Кострюков Евгений, студент группы М8О-407Б-22

---

## Содержание репозитория
- **`notebooks/`** - папка с Jupyter Notebooks:
  - `lab1.ipynb` - KNN: классификация и регрессия;
  - `lab2.ipynb` - Логистическая и линейная регрессия;
  - `lab3.ipynb` - Решающие деревья;
  - `lab4.ipynb` - Случайный лес;
  - `lab5.ipynb` - Градиентный бустинг и итоговое сравнение алгоритмов.
- **`data/`** - папка с исходными наборами данных: 
  - `City_Types.csv` - для классификации;  
  - `House_Price_Prediction.csv` - для регрессии.  

---

## Описание датасетов

### 1) Классификация: *Industrial vs Residential* (Air Quality)
- Короткое описание: классификация типа зоны (Industrial / Residential) по показателям качества воздуха и дополнительным признакам (город, временные признаки и т.д.);
- Источник: [Kaggle — Industrial-Residential Air Quality Classification](https://www.kaggle.com/datasets/youssefelebiary/industrial-residential-air-quality-classification)
- Используемые файлы: `data/City_Types.csv` (52 705 строк, 9 параметров).

### 2) Регрессия: *House Price Prediction*
- Короткое описание: предсказание цены недвижимости на основе характеристик объявления и объекта;
- Источник: [Kaggle — House Price Prediction Challenge](https://www.kaggle.com/datasets/anmolkumar/house-price-prediction-challenge)
- Используемые файлы: `data/House_Price_Prediction.csv` (29451 строк, 12 столбцов).

---

## Краткое содержание каждой лабораторной

### ЛР1 (`notebooks/lab1.ipynb`)
- Выбор наборов данных (классификация и регрессия) и обоснование выбора;
- Построение бейзлайна: обучение моделей sklearn (KNeighborsClassifier и KNeighborsRegressor), оценка метрик;
- Формирование гипотез по улучшению: масштабирование, создание новых признаков (временные — hour/day_of_week/month для классификации; LOG_SQFT и SQFT_PER_ROOM для регрессии), подбор гиперпараметра k на кросс-валидации;
- Улучшенный бейзлайн: обучение и сравнение метрик;
- Собственная имплементация MyKNNClassifier и MyKNNRegressor (с нуля), обучение и сравнение с sklearn;
- В ноутбуке присутствуют комментарии минимум к каждой ячейке и выводы по каждому пункту.

### ЛР2 (`notebooks/lab2.ipynb`)
- Повтор пунктов 2-4 из ЛР1, но с использованием LogisticRegression (для классификации) и LinearRegression / Ridge / Lasso (для регрессии);
- Подбор гиперпараметров, сравнение с KNN.

### ЛР3 - Дерево решений (`notebooks/lab3.ipynb`)
- Повтор пунктов 2–4 из ЛР1 с DecisionTreeClassifier и DecisionTreeRegressor;
- Включает визуализацию дерева (graphviz / sklearn.plot_tree) и анализ важности признаков.

### ЛР4 (`notebooks/lab4.ipynb`)
- Повтор пунктов 2–4 из ЛР1 с RandomForestClassifier/Regressor;
- OOB-оценки, подбор числа деревьев, max_depth, feature_importances.

### ЛР5 (`notebooks/lab5.ipynb`)
- Повтор пунктов 2–4 из ЛР1 с GradientBoosting/XGBoost/LightGBM (в зависимости от доступных библиотек);
- Итоговое сравнение всех алгоритмов (KNN, Logistic/Linear, Decision Tree, Random Forest, Gradient Boosting): таблица метрик, сравнительный график, выводы по устойчивости и качеству.

---

## Краткие выводы по ЛР1
- **Классификация (KNN)**:
  - Baseline KNN без масштабирования показал высокую точность (Accuracy = 0.98, F1 = 0.98).
  - Улучшенный бейзлайн с масштабированием числовых признаков, добавлением временных признаков (hour, day_of_week, month) и подбором k через кросс-валидацию достиг идеальных метрик (Accuracy = 1.0, F1 = 1.0).
  - Собственная реализация `MyKNNClassifier` полностью повторяет поведение sklearn KNN на улучшенном бейзлайне, подтверждая корректность имплементации.

- **Регрессия (KNNRegressor)**:
  - Baseline KNN показал умеренное качество (R^2 = 0.59, MAE = 66.8), без масштабирования и новых признаков.
  - Добавление информативных признаков (LOG_SQFT, SQFT_PER_ROOM) и масштабирование числовых данных повысили R^2 до 0.67 и снизили MAE до 47.
  - Собственная реализация `MyKNNRegressor` с улучшенным бейзлайном показывает метрики, сопоставимые со sklearn KNN, подтверждая правильность работы алгоритма и эффективность выбранного препроцессинга.

---

## Краткие выводы по ЛР2


---

## Краткие выводы по ЛР3


---

## Краткие выводы по ЛР4



---
## Краткие выводы по ЛР5


---

## Инструкция по запуску

Так как ноутбуки выполнялись в **Google Colab**, запуск происходит следующим образом:

1. Перейдите в [Google Colab](https://colab.research.google.com/).  
2. Нажмите **File -> Upload notebook** и выберите нужный файл (`lab1.ipynb`, `lab2.ipynb` и т.д.) из папки `notebooks/`.  
3. Для работы с данными:
   - Скачайте файлы `City_Types.csv` и `House_Price_Prediction.csv` из папки `data/` или с Kaggle;
   - Загрузите их в Colab через левое меню.
4. Выполните все ячейки ноутбука.