# Прикладные системы и фреймворки искусственного интеллекта

Репозиторий содержит результаты пяти лабораторных работ по курсу «Прикладные системы и фреймворки искусственного интеллекта». Каждая лабораторная работа выполнена в формате Jupyter Notebook с подробными комментариями к каждой ячейке.

---

## Выполнил: Кострюков Евгений, студент группы М8О-407Б-22

---

## Содержание репозитория
- **`notebooks/`** - папка с Jupyter Notebooks:
  - `lab1.ipynb` - KNN: классификация и регрессия;
  - `lab2.ipynb` - Логистическая и линейная регрессия;
  - `lab3.ipynb` - Решающие деревья;
  - `lab4.ipynb` - Случайный лес;
  - `lab5.ipynb` - Градиентный бустинг и итоговое сравнение алгоритмов.
- **`data/`** - папка с исходными наборами данных: 
  - `diabetes_dataset.csv` - для классификации;  
  - `House_Price_Prediction.csv` - для регрессии.  

---

## Описание датасетов

### 1) Классификация: *Diabetes Prediction Dataset*
- Короткое описание: бинарная классификация - определение наличия диабета по медицинским показателям (возраст, пол, индекс массы тела, глюкоза, HbA1c и т.д.);
- Источник: [Kaggle - Diabetes Prediction Dataset](https://www.kaggle.com/datasets/priyamchoksi/100000-diabetes-clinical-dataset)
- Используемые файлы: `data/diabetes_dataset.csv` (100000 строк, 16 параметров).

### 2) Регрессия: *House Price Prediction*
- Короткое описание: предсказание цены недвижимости на основе характеристик объявления и объекта;
- Источник: [Kaggle - House Price Prediction Challenge](https://www.kaggle.com/datasets/anmolkumar/house-price-prediction-challenge)
- Используемые файлы: `data/House_Price_Prediction.csv` (29451 строк, 12 столбцов).

---

## Краткое содержание каждой лабораторной

### ЛР1 (`notebooks/lab1.ipynb`)
- Выбор наборов данных (классификация и регрессия) и обоснование выбора;
- Построение бейзлайна: обучение моделей sklearn (KNeighborsClassifier и KNeighborsRegressor), оценка метрик;
- Формирование гипотез по улучшению: масштабирование, создание новых признаков (временные - hour/day_of_week/month для классификации; LOG_SQFT и SQFT_PER_ROOM для регрессии), подбор гиперпараметра k на кросс-валидации;
- Улучшенный бейзлайн: обучение и сравнение метрик;
- Собственная имплементация MyKNNClassifier и MyKNNRegressor (с нуля), обучение и сравнение с sklearn;
- В ноутбуке присутствуют комментарии минимум к каждой ячейке и выводы по каждому пункту.

### ЛР2 (`notebooks/lab2.ipynb`)
- Повтор пунктов 2-4 из ЛР1, но с использованием LogisticRegression (для классификации) и LinearRegression (для регрессии).

### ЛР3 (`notebooks/lab3.ipynb`)
- Повтор пунктов 2-4 из ЛР1 с DecisionTreeClassifier и DecisionTreeRegressor.

### ЛР4 (`notebooks/lab4.ipynb`)
- Повтор пунктов 2-4 из ЛР1 с RandomForestClassifier/Regressor.

### ЛР5 (`notebooks/lab5.ipynb`)
- Повтор пунктов 2-4 из ЛР1 с GradientBoosting;
- Итоговое сравнение всех алгоритмов (KNN, Logistic/Linear, Decision Tree, Random Forest, Gradient Boosting).

---

## Краткие выводы по ЛР1
- **Классификация**:
  - Baseline KNN на исходных данных показал высокую Accuracy = 0.957, но при этом Recall оставался умеренным (0.56), что связано с дисбалансом классов и зависимостью KNN от масштаба признаков;
  - Масштабирование числовых признаков дало минимальные изменения метрик, что ожидаемо для KNN - расстояния меняются, но структура данных остаётся прежней;
  - Добавление категориальных признаков (BMI class, HbA1c class) привело к умеренному росту Recall (с 0.56 до 0.58) и увеличению F1-score. Это говорит о том, что новые признаки действительно несут полезную информацию;
  - Подбор оптимального k через кросс-валидацию показал, что оптимальное значение K = 9, что слегка отличается от baseline K = 5. Изменение числа соседей в данном случае также не привело к значительным улучшениям, так как датасет большой и классы относительно хорошо разделяются;
  - Собственная реализация MyKNNClassifier полностью совпала по метрикам с sklearn-версией, что подтверждает корректность имплементации и правильно выбранную обработку входных данных.

- **Регрессия**:
  - Baseline KNN показал умеренное качество (R^2 = 0.59, MAE = 66.8);
  - Добавление информативных признаков (LOG_SQFT, SQFT_PER_ROOM) и масштабирование числовых данных повысили R^2 до 0.67 и снизили MAE до 47;
  - Собственная реализация MyKNNRegressor совпала по качеству с sklearn KNN, что подтверждает корректность работы алгоритма на улучшенных данных.

---

## Краткие выводы по ЛР2
- **Логистическая регрессия (классификация)**:
  - Улучшение признаков (масштабирование + BMI/HbA1c в виде категорий) дало заметный рост качества. Подбор параметра C слегка улучшил F1. Собственная реализация логистической регрессии показала такие же результаты, что подтверждает корректность алгоритма.

- **Линейная регрессия (регрессия)**:
  - Baseline работал слабее из-за мультиколлинеарности и немасштабированных данных. Добавление новых признаков и удаление лишних резко улучшило качество (R^2 вырос до 0.67). Ridge почти не изменил метрики. Собственная реализация полностью совпала с sklearn.

---

## Краткие выводы по ЛР3
- **Классификация (DecisionTreeClassifier)**:
  - Baseline дерево показало высокую Accuracy (0.956) и более высокий Recall, чем логистическая регрессия, что важно для медицинской задачи. Подбор глубины и min_samples_leaf значительно улучшил модель: F1 вырос с 0.74 до 0.805, Precision стал равен 1.0, что снизило переобучение и сделало модель более устойчивой. Собственная реализация дерева полностью совпала по метрикам с sklearn, что подтверждает корректность имплементации.

- **Регрессия (DecisionTreeRegressor)**:
  - Дерево значительно превзошло линейную регрессию: MAE снизился с 131 до 39, RMSE - с 569 до 350, а R^2 вырос с 0.41 до 0.78. Проверенные гипотезы (новые признаки, ограничение глубины, настройка параметров узлов) дали минимальное улучшение или лёгкое ухудшение - модель уже была близка к максимуму качества, и дальнейшие локальные изменения практически не влияют на метрики.

---

## Краткие выводы по ЛР4
- **Классификация (RandomForestClassifier)**:
  - Baseline Random Forest показал высокое качество: Accuracy = 0.972, Precision = 0.994, Recall = 0.678, F1-score = 0.806. Модель значительно улучшила Precision по сравнению с одиночным деревом, сохранив высокий уровень обнаружения реальных случаев диабета;
  - Ограничение глубины деревьев и подбор min_samples_leaf оказали минимальное влияние на F1-score, что демонстрирует устойчивость Random Forest к переобучению;
  - Добавление категориальных признаков на основе BMI и HbA1c дало небольшое улучшение F1-score (0.806 -> 0.807), показывая, что новые признаки повышают информативность модели;
  - Собственная реализация Random Forest воспроизвела основные принципы ансамбля и показала метрики, сопоставимые с sklearn, подтверждая корректность имплементации;
  - Улучшенный бейзлайн сделал модель более консервативной: Precision достиг 1.0, Recall немного снизился, F1-score остался высоким, обеспечивая хороший баланс метрик.

- **Регрессия (RandomForestRegressor)**:
  - Baseline Random Forest показал стабильное качество предсказаний: MAE = 34.97, RMSE = 375.08, R^2 = 0.742, превосходя одиночное дерево по MAE;
  - Добавление новых признаков (LOG_SQFT, SQFT_PER_ROOM), подбор оптимальной глубины деревьев и настройка min_samples_leaf позволили улучшить R^2 до 0.835 и снизить RMSE до 300.21, что подтверждает эффективность улучшенного бейзлайна;
  - Собственная реализация Random Forest для регрессии показала сопоставимые с sklearn результаты, что подтверждает корректность алгоритма и его способность к качественному предсказанию даже на улучшенном бейзлайне.

---

## Краткие выводы по ЛР5
- **Классификация (GradientBoostingClassifier)**:
  - Базовый градиентный бустинг показал одно из лучших качеств среди всех рассмотренных алгоритмов: Accuracy = 0.973, Recall = 0.689 и F1-score = 0.811, слегка превзойдя Random Forest по полноте и F1-score;
  - Проверка гипотез (подбор глубины деревьев, добавление категориальных признаков BMI и HbA1c, настройка min_samples_leaf) привела лишь к незначительным изменениям метрик, что указывает на высокую устойчивость Gradient Boosting к настройке гиперпараметров;
  - Улучшенный бейзлайн не превзошёл стандартный вариант: Precision немного снизился, Recall остался неизменным, а F1-score уменьшился, поэтому стандартный бейзлайн оказался наиболее сбалансированным;
  - Собственная реализация Gradient Boosting Classifier показала метрики, близкие к sklearn, с более консервативным поведением (Precision = 1.0 при меньшем Recall), что подтверждает корректность имплементации.

- **Регрессия (GradientBoostingRegressor)**:
  - Baseline Gradient Boosting продемонстрировал хорошую объясняющую способность (R^2 = 0.785), превосходя Random Forest по R^2, но уступая ему по MAE;
  - Добавление новых информативных признаков (LOG_SQFT, SQFT_PER_ROOM, DIST_TO_CENTER) и настройка гиперпараметров (max_depth, learning_rate) привели к существенному улучшению качества: R^2 вырос до 0.927, а RMSE снизился почти в 2 раза;
  - Улучшенный бейзлайн GradientBoostingRegressor показал лучшие результаты среди всех рассмотренных регрессионных моделей;
  - Собственная реализация Gradient Boosting для регрессии при малом числе деревьев показала худшие метрики, что объясняется вычислительными ограничениями, а не ошибками алгоритма. При увеличении n_estimators её поведение будет приближаться к sklearn.

---

## Итоговое сравнение алгоритмов (ЛР1–ЛР5)
- **Классификация (Diabetes Prediction)**:
  - Линейные модели (Logistic Regression) показали стабильное, но ограниченное качество. Они хорошо интерпретируемы, однако уступают нелинейным методам по Recall и F1-score, что критично для медицинской задачи;
  - KNN продемонстрировал высокую Accuracy, но чувствительность к масштабированию и умеренный Recall ограничивают его практическую применимость;
  - Решающее дерево обеспечило более высокий Recall по сравнению с линейными моделями, однако без ограничений глубины склонно к переобучению;
  - Random Forest значительно повысил стабильность и Precision, сохранив высокий Recall. Это сделало его сильным и надёжным алгоритмом для данной задачи;
  - Gradient Boosting показал наилучший баланс метрик: максимальный Recall (0.689) и наивысший F1-score (0.811) среди всех алгоритмов. При этом дополнительные улучшения бейзлайна дали минимальный эффект, что говорит о высокой оптимальности стандартной конфигурации.

Итог по классификации:
Градиентный бустинг оказался наиболее эффективным алгоритмом, обеспечив лучшую способность выявления реальных случаев диабета при высоком общем качестве. Random Forest занял второе место, а линейные модели и KNN уступили ансамблевым методам.

- **Регрессия (House Price Prediction)**:
  - Линейная регрессия показала слабое качество на baseline из-за нелинейных зависимостей и мультиколлинеарности, однако заметно улучшилась после инженерии признаков;
  - KNN-регрессия дала умеренные результаты и сильно зависела от масштабирования и плотности данных;
  - Решающее дерево резко улучшило качество по сравнению с линейными моделями, но страдало от нестабильности и чувствительности к параметрам;
  - Random Forest обеспечил хорошую среднюю точность (низкий MAE) и стабильность, однако не достиг максимального R^2;
  - Gradient Boosting стал лучшей моделью для регрессии: после добавления информативных признаков и настройки гиперпараметров R^2 вырос до 0.93, а RMSE снизился почти вдвое по сравнению с baseline.

Итог по регрессии:
Gradient Boosting Regresor показал наилучшую объясняющую способность и минимальные ошибки, превзойдя Random Forest и остальные алгоритмы. Основной вклад в улучшение качества внесли feature engineering и корректная настройка гиперпараметров.

---

## Общий итог по всем лабораторным работам
- По мере перехода от простых моделей (KNN, линейные) к ансамблевым (Random Forest, Gradient Boosting) наблюдается монотонный рост качества как в классификации, так и в регрессии;
- Ансамблевые методы оказались наиболее универсальными и устойчивыми к шуму и переобучению;
- Gradient Boosting стал лучшим алгоритмом в обеих задачах, продемонстрировав максимальное качество при разумной настройке;
- Собственные реализации всех алгоритмов корректно воспроизводят поведение sklearn-моделей, а различия в метриках объясняются отсутствием оптимизаций и вычислительными ограничениями.

Вывод:
В рамках всех пяти лабораторных работ градиентный бустинг подтвердил себя как наиболее мощный и универсальный метод машинного обучения для реальных прикладных задач, особенно при наличии качественного препроцессинга и информативных признаков.

---

## Инструкция по запуску

Так как ноутбуки выполнялись в **Google Colab**, запуск происходит следующим образом:

1. Перейдите в [Google Colab](https://colab.research.google.com/).  
2. Нажмите **File -> Upload notebook** и выберите нужный файл (`lab1.ipynb`, `lab2.ipynb` и т.д.) из папки `notebooks/`.  
3. Для работы с данными:
   - Скачайте файлы `diabetes_dataset.csv` и `House_Price_Prediction.csv` из папки `data/` или с Kaggle;
   - Загрузите их в Colab через левое меню.
4. Выполните все ячейки ноутбука.
